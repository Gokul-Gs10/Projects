{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1099232,"sourceType":"datasetVersion","datasetId":614679}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, \n                                     GlobalAveragePooling2D, Dense, Add, Dropout)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T06:27:20.083424Z","iopub.execute_input":"2025-03-12T06:27:20.083708Z","iopub.status.idle":"2025-03-12T06:27:32.707987Z","shell.execute_reply.started":"2025-03-12T06:27:20.083677Z","shell.execute_reply":"2025-03-12T06:27:32.707040Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Define dataset path\ndataset_path = \"/kaggle/input/medical-mnist\"\ncategories = ['AbdomenCT', 'BreastMRI', 'Hand', 'CXR', 'HeadCT', 'ChestCT']\ncategory_labels = {cat: idx for idx, cat in enumerate(categories)}\n\n# Load images and labels\ninput_set, label_set = [], []\nfor category in categories:\n    category_path = os.path.join(dataset_path, category)\n    for img_file in os.listdir(category_path):\n        img_path = os.path.join(category_path, img_file)\n        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        image = cv2.resize(image, (64, 64))\n        input_set.append(image)\n        label_set.append(category_labels[category])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T06:27:32.709447Z","iopub.execute_input":"2025-03-12T06:27:32.710068Z","iopub.status.idle":"2025-03-12T06:33:48.710227Z","shell.execute_reply.started":"2025-03-12T06:27:32.710033Z","shell.execute_reply":"2025-03-12T06:33:48.709441Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Check class distribution\nclass_counts = Counter(label_set)\nprint(f\"Class Distribution: {class_counts}\")\n\n# Convert to numpy arrays\ninput_set = np.array(input_set).reshape(-1, 64, 64, 1) / 255.0  # Normalize\nlabel_set = tf.keras.utils.to_categorical(np.array(label_set), num_classes=len(categories))\n\n# Train-test split\nsplit_index = int(0.8 * len(input_set))\ntrain_set, test_set = input_set[:split_index], input_set[split_index:]\ntrain_labels, test_labels = label_set[:split_index], label_set[split_index:]\n\n# Shuffle data\ntrain_set, train_labels = shuffle(train_set, train_labels, random_state=42)\ntest_set, test_labels = shuffle(test_set, test_labels, random_state=42)\n\n# Split the training data into 4 equal parts for local models\nsplit_size = len(train_set) // 4\nlocal_datasets = [\n    (train_set[i * split_size: (i + 1) * split_size], train_labels[i * split_size: (i + 1) * split_size])\n    for i in range(4)\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T06:33:48.713444Z","iopub.execute_input":"2025-03-12T06:33:48.713672Z","iopub.status.idle":"2025-03-12T06:33:50.017463Z","shell.execute_reply.started":"2025-03-12T06:33:48.713652Z","shell.execute_reply":"2025-03-12T06:33:50.016801Z"}},"outputs":[{"name":"stdout","text":"Class Distribution: Counter({0: 10000, 2: 10000, 3: 10000, 4: 10000, 5: 10000, 1: 8954})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Data Augmentation\ndata_gen = ImageDataGenerator(\n    rotation_range=15,  # Rotate images randomly\n    width_shift_range=0.1,  # Shift width by 10%\n    height_shift_range=0.1,  # Shift height by 10%\n    zoom_range=0.2,  # Zoom by 20%\n    horizontal_flip=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T06:33:50.019298Z","iopub.execute_input":"2025-03-12T06:33:50.019599Z","iopub.status.idle":"2025-03-12T06:33:50.023025Z","shell.execute_reply.started":"2025-03-12T06:33:50.019576Z","shell.execute_reply":"2025-03-12T06:33:50.022223Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Define Improved ResNet-based model\ndef residual_block(x, filters, kernel_size=3, strides=1):\n    shortcut = x\n    x = Conv2D(filters, kernel_size, strides=strides, padding='same', kernel_initializer='he_normal')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n    x = BatchNormalization()(x)\n    \n    if strides != 1 or shortcut.shape[-1] != filters:\n        shortcut = Conv2D(filters, (1, 1), strides=strides, padding='same', kernel_initializer='he_normal')(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n    \n    x = Add()([x, shortcut])\n    x = Activation('relu')(x)\n    return x\n\ndef create_resnet(input_shape, num_classes):\n    inputs = Input(shape=input_shape)\n    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', kernel_initializer='he_normal')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\n    x = residual_block(x, 64)\n    x = residual_block(x, 128, strides=2)\n    x = residual_block(x, 256, strides=2)\n    x = residual_block(x, 512, strides=2)\n    x = residual_block(x, 1024, strides=2)  # Increased depth\n    \n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.3)(x)  # Reduced dropout\n    outputs = Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.0005))(x)\n\n    return Model(inputs, outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T06:33:50.023951Z","iopub.execute_input":"2025-03-12T06:33:50.024182Z","iopub.status.idle":"2025-03-12T06:33:50.040898Z","shell.execute_reply.started":"2025-03-12T06:33:50.024155Z","shell.execute_reply":"2025-03-12T06:33:50.040273Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Federated averaging function with normalization\ndef fedavg(*models):\n    all_weights = [model.get_weights() for model in models]\n    averaged_weights = [\n        np.mean(np.array([weights[i] for weights in all_weights]), axis=0)\n        for i in range(len(all_weights[0]))\n    ]\n    return averaged_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T06:33:50.041656Z","iopub.execute_input":"2025-03-12T06:33:50.041890Z","iopub.status.idle":"2025-03-12T06:33:50.057614Z","shell.execute_reply.started":"2025-03-12T06:33:50.041871Z","shell.execute_reply":"2025-03-12T06:33:50.056829Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initialize global model\nglobal_model = create_resnet((64, 64, 1), len(categories))\nglobal_model.compile(\n    optimizer=Adam(learning_rate=0.0003, beta_1=0.9),  # Lower learning rate\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\nglobalweights = global_model.get_weights()\n\n# Local models\nmodels = [create_resnet((64, 64, 1), len(categories)) for _ in range(4)]\nfor model in models:\n    model.compile(\n        optimizer=Adam(learning_rate=0.0003, beta_1=0.9),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    model.set_weights(globalweights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T06:33:50.058481Z","iopub.execute_input":"2025-03-12T06:33:50.058740Z","iopub.status.idle":"2025-03-12T06:33:54.073218Z","shell.execute_reply.started":"2025-03-12T06:33:50.058713Z","shell.execute_reply":"2025-03-12T06:33:54.072501Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Training parameters\nepochs = 10  # Increased local epochs\nbatch_size = 16\nset_rounds = 12\nRoundsUp = 0\ndoYouWantToRunMore = \"yes\"\n\nwhile doYouWantToRunMore == \"yes\":\n    for i, model in enumerate(models):\n        x_train_local, y_train_local = local_datasets[i]\n        print(f\"Training local model {i+1}...\")\n\n        early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n        reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=1e-6)\n\n        model.fit(\n            data_gen.flow(x_train_local, y_train_local, batch_size=batch_size),\n            epochs=epochs,\n            callbacks=[early_stopping, reduce_lr]\n        )\n    \n    averaged_weights = fedavg(*models)\n    global_model.set_weights(averaged_weights)\n    for model in models:\n        model.set_weights(averaged_weights)\n    \n    loss, accuracy = global_model.evaluate(test_set, test_labels, batch_size=8)\n    print(f'Round {RoundsUp + 1}: Loss = {loss}, Accuracy = {accuracy}')\n    RoundsUp += 1","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-12T07:41:28.150Z"}},"outputs":[],"execution_count":null}]}