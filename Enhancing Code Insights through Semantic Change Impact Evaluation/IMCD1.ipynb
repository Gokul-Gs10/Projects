{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzKWuU7I-43e",
        "outputId": "a8f2ba1c-fd65-417c-d762-4a700b38fa77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Changes Detected: False\n",
            "Refactoring Detected: False\n",
            "Potential refactoring detected in commit message: Refactor the add function for clarity\n",
            "Code differences:\n",
            "Operation: equal, Original Lines: ['def add(a, b):', '    return a + b', 'result = add(5, 3)'], Modified Lines: ['def add(a, b):', '    return a + b', 'result = add(5, 3)']\n",
            "Comments:\n",
            "This change looks good!\n",
            "Consider renaming 'add' function to 'sum'\n",
            "Documentation generated.\n"
          ]
        }
      ],
      "source": [
        "import ast\n",
        "import difflib\n",
        "import tokenize\n",
        "from io import BytesIO\n",
        "\n",
        "# Semantic Analysis\n",
        "\n",
        "def analyze_semantics(code):\n",
        "    \"\"\"Perform semantic analysis on the given code.\"\"\"\n",
        "    # Example: check for undefined variables\n",
        "    try:\n",
        "        compiled_code = compile(code, '<string>', 'exec')\n",
        "        exec(compiled_code)\n",
        "    except Exception as e:\n",
        "        print(f\"Semantic error: {e}\")\n",
        "\n",
        "# Change Detection\n",
        "\n",
        "def detect_changes(original_code, modified_code):\n",
        "    \"\"\"Detect semantic changes between original and modified code.\"\"\"\n",
        "    original_ast = ast.parse(original_code)\n",
        "    modified_ast = ast.parse(modified_code)\n",
        "\n",
        "    # Compare ASTs to identify semantic changes\n",
        "    return not ast.dump(original_ast) == ast.dump(modified_ast)\n",
        "\n",
        "# Refactoring Detection\n",
        "\n",
        "def detect_refactorings(original_code, modified_code):\n",
        "    \"\"\"Detect refactorings between original and modified code.\"\"\"\n",
        "    # Example: check if variable names have changed\n",
        "    original_tokens = tokenize_code(original_code)\n",
        "    modified_tokens = tokenize_code(modified_code)\n",
        "    return original_tokens != modified_tokens\n",
        "\n",
        "# Code Diffing\n",
        "\n",
        "def compute_diff(original_code, modified_code):\n",
        "    \"\"\"Compute semantic differences between original and modified code.\"\"\"\n",
        "    original_ast = ast.parse(original_code)\n",
        "    modified_ast = ast.parse(modified_code)\n",
        "    diff = difflib.SequenceMatcher(None, ast.dump(original_ast), ast.dump(modified_ast)).get_opcodes()\n",
        "\n",
        "    # Convert diff operations to human-readable format\n",
        "    diff_info = []\n",
        "    for tag, i1, i2, j1, j2 in diff:\n",
        "        diff_info.append((tag, original_code.splitlines()[i1:i2], modified_code.splitlines()[j1:j2]))\n",
        "\n",
        "    return diff_info\n",
        "\n",
        "def tokenize_code(code):\n",
        "    \"\"\"Tokenize the given code.\"\"\"\n",
        "    tokens = []\n",
        "    code_bytes = BytesIO(code.encode('utf-8')).readline\n",
        "    try:\n",
        "        for token in tokenize.tokenize(code_bytes):\n",
        "            tokens.append(token)\n",
        "    except tokenize.TokenError:\n",
        "        pass  # Ignore tokenization errors\n",
        "    return tokens\n",
        "\n",
        "# Integration with Version Control Systems\n",
        "'''\n",
        "def analyze_version_control_changes(commit_diff):\n",
        "    \"\"\"Analyze code changes in version control commits.\"\"\"\n",
        "    # Example: check for changes in function signatures\n",
        "    for original_code, modified_code in commit_diff:\n",
        "        diff = compute_diff(original_code, modified_code)\n",
        "        print(\"Code differences:\")\n",
        "        for tag, orig_lines, mod_lines in diff:\n",
        "            print(f\"Operation: {tag}, Original Lines: {orig_lines}, Modified Lines: {mod_lines}\")\n",
        "'''\n",
        "# Natural Language Processing (NLP)\n",
        "\n",
        "def analyze_commit_messages(commit_messages):\n",
        "    \"\"\"Analyze commit messages using NLP.\"\"\"\n",
        "    # Example: detect if the commit message contains keywords related to refactorings\n",
        "    for message in commit_messages:\n",
        "        if 'refactor' in message.lower():\n",
        "            print(\"Potential refactoring detected in commit message:\", message)\n",
        "\n",
        "# Collaborative Tools\n",
        "\n",
        "def provide_collaborative_feedback(code_diff, comments):\n",
        "    \"\"\"Provide collaborative feedback on code differences.\"\"\"\n",
        "    # Example: display code differences and allow developers to leave comments\n",
        "    print(\"Code differences:\")\n",
        "    for tag, orig_lines, mod_lines in code_diff:\n",
        "        print(f\"Operation: {tag}, Original Lines: {orig_lines}, Modified Lines: {mod_lines}\")\n",
        "    print(\"Comments:\")\n",
        "    for comment in comments:\n",
        "        print(comment)\n",
        "\n",
        "# Documentation and Tutorials\n",
        "\n",
        "def generate_documentation():\n",
        "    \"\"\"Generate documentation and tutorials for the tool.\"\"\"\n",
        "    # Example: generate documentation explaining tool usage, concepts, etc.\n",
        "    print(\"Documentation generated.\")\n",
        "\n",
        "# Main function\n",
        "\n",
        "def main():\n",
        "    # Example code snippets for testing\n",
        "    original_code = '''def add(a, b):\n",
        "    return a + b\n",
        "result = add(5, 3)'''\n",
        "\n",
        "    modified_code = '''def add(a, b):\n",
        "    return a + b\n",
        "result = add(5, 3)'''\n",
        "\n",
        "    # Example usage of functions\n",
        "    analyze_semantics(original_code)\n",
        "    semantic_changes_detected = detect_changes(original_code, modified_code)\n",
        "    print(\"Semantic Changes Detected:\", semantic_changes_detected)\n",
        "    refactoring_detected = detect_refactorings(original_code, modified_code)\n",
        "    print(\"Refactoring Detected:\", refactoring_detected)\n",
        "    opcodes = compute_diff(original_code, modified_code)\n",
        "    #analyze_version_control_changes([(original_code, modified_code)])\n",
        "    commit_messages = [\"Refactor the add function for clarity\", \"Fix bug in result calculation\"]\n",
        "    analyze_commit_messages(commit_messages)\n",
        "    comments = [\"This change looks good!\", \"Consider renaming 'add' function to 'sum'\"]\n",
        "    provide_collaborative_feedback(opcodes, comments)\n",
        "    generate_documentation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import difflib\n",
        "import tokenize\n",
        "from io import BytesIO\n",
        "\n",
        "# Semantic Analysis\n",
        "\n",
        "def analyze_semantics(code):\n",
        "    \"\"\"Perform semantic analysis on the given code.\"\"\"\n",
        "    # Example: check for undefined variables\n",
        "    try:\n",
        "        compiled_code = compile(code, '<string>', 'exec')\n",
        "        exec(compiled_code)\n",
        "    except Exception as e:\n",
        "        print(f\"Semantic error: {e}\")\n",
        "\n",
        "# Change Detection\n",
        "\n",
        "def detect_changes(original_code, modified_code):\n",
        "    \"\"\"Detect semantic changes between original and modified code.\"\"\"\n",
        "    original_ast = ast.parse(original_code)\n",
        "    modified_ast = ast.parse(modified_code)\n",
        "\n",
        "    # Compare ASTs to identify semantic changes\n",
        "    return not ast.dump(original_ast) == ast.dump(modified_ast)\n",
        "\n",
        "# Refactoring Detection\n",
        "\n",
        "def detect_refactorings(original_code, modified_code):\n",
        "    \"\"\"Detect refactorings between original and modified code.\"\"\"\n",
        "    # Example: check if variable names have changed\n",
        "    original_tokens = tokenize_code(original_code)\n",
        "    modified_tokens = tokenize_code(modified_code)\n",
        "    return original_tokens != modified_tokens\n",
        "\n",
        "# Code Diffing\n",
        "\n",
        "def compute_diff(original_code, modified_code):\n",
        "    \"\"\"Compute semantic differences between original and modified code.\"\"\"\n",
        "    original_lines = original_code.splitlines()\n",
        "    modified_lines = modified_code.splitlines()\n",
        "\n",
        "    diff = difflib.SequenceMatcher(None, original_lines, modified_lines).get_opcodes()\n",
        "\n",
        "    # Filter out non-essential differences\n",
        "    diff_info = []\n",
        "    for tag, i1, i2, j1, j2 in diff:\n",
        "        if tag == 'replace':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            # Check if the lines contain actual code\n",
        "            if any(line.strip() for line in original_content) or any(line.strip() for line in modified_content):\n",
        "                diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "        elif tag != 'equal':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "\n",
        "    return diff_info\n",
        "\n",
        "def tokenize_code(code):\n",
        "    \"\"\"Tokenize the given code.\"\"\"\n",
        "    tokens = []\n",
        "    code_bytes = BytesIO(code.encode('utf-8')).readline\n",
        "    try:\n",
        "        for token in tokenize.tokenize(code_bytes):\n",
        "            tokens.append(token)\n",
        "    except tokenize.TokenError:\n",
        "        pass  # Ignore tokenization errors\n",
        "    return tokens\n",
        "\n",
        "# Natural Language Processing (NLP)\n",
        "\n",
        "def analyze_commit_messages(commit_messages):\n",
        "    \"\"\"Analyze commit messages using NLP.\"\"\"\n",
        "    # Example: detect if the commit message contains keywords related to refactorings\n",
        "    for message in commit_messages:\n",
        "        if 'refactor' in message.lower():\n",
        "            print(\"Potential refactoring detected in commit message:\", message)\n",
        "\n",
        "# Collaborative Tools\n",
        "\n",
        "def provide_collaborative_feedback(code_diff, comments):\n",
        "    \"\"\"Provide collaborative feedback on code differences.\"\"\"\n",
        "    # Example: display code differences and allow developers to leave comments\n",
        "    print(\"Code differences:\")\n",
        "    for tag, i1, i2, j1, j2, orig_lines, mod_lines in code_diff:\n",
        "        print(f\"Operation: {tag}, Original Lines {i1}-{i2}: {orig_lines}, Modified Lines {j1}-{j2}: {mod_lines}\")\n",
        "    print(\"Comments:\")\n",
        "    for comment in comments:\n",
        "        print(comment)\n",
        "\n",
        "# Documentation and Tutorials\n",
        "\n",
        "def generate_documentation():\n",
        "    \"\"\"Generate documentation and tutorials for the tool.\"\"\"\n",
        "    # Example: generate documentation explaining tool usage, concepts, etc.\n",
        "    print(\"Documentation generated.\")\n",
        "\n",
        "# Main function\n",
        "\n",
        "def main():\n",
        "    # Define dataset paths\n",
        "    original_dataset_path = \"/content/original.py\"\n",
        "    modified_dataset_path = \"/content/modified.py\"\n",
        "\n",
        "    # Load datasets\n",
        "    with open(original_dataset_path, 'r') as original_file:\n",
        "        original_code = original_file.read()\n",
        "    with open(modified_dataset_path, 'r') as modified_file:\n",
        "        modified_code = modified_file.read()\n",
        "\n",
        "    # Example usage of functions\n",
        "    print(\"Output for original code:\")\n",
        "    exec(original_code)\n",
        "    print(\"\\nOutput for modified code:\")\n",
        "    exec(modified_code)\n",
        "\n",
        "    # Example usage of semantic analysis functions\n",
        "    analyze_semantics(original_code)\n",
        "    semantic_changes_detected = detect_changes(original_code, modified_code)\n",
        "    print(\"\\nSemantic Changes Detected:\", semantic_changes_detected)\n",
        "    refactoring_detected = detect_refactorings(original_code, modified_code)\n",
        "    print(\"Refactoring Detected:\", refactoring_detected)\n",
        "\n",
        "    # Compute code differences\n",
        "    opcodes = compute_diff(original_code, modified_code)\n",
        "\n",
        "    # Analyze commit messages\n",
        "    commit_messages = [\"Refactor the add function for clarity\", \"Fix bug in result calculation\"]\n",
        "    analyze_commit_messages(commit_messages)\n",
        "\n",
        "    # Provide collaborative feedback\n",
        "    comments = [\"This change looks good!\", \"Consider renaming 'add' function to 'sum'\"]\n",
        "    provide_collaborative_feedback(opcodes, comments)\n",
        "\n",
        "    # Generate documentation\n",
        "    generate_documentation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYGTjHZD--Af",
        "outputId": "a7eaae84-23e0-46a1-d340-34d8126859c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for original code:\n",
            "Result: 8\n",
            "\n",
            "Output for modified code:\n",
            "Result: 8\n",
            "Result: 8\n",
            "\n",
            "Semantic Changes Detected: True\n",
            "Refactoring Detected: True\n",
            "Potential refactoring detected in commit message: Refactor the add function for clarity\n",
            "Code differences:\n",
            "Operation: replace, Original Lines 1-1: ['# original.py'], Modified Lines 1-1: ['# modified.py']\n",
            "Operation: replace, Original Lines 6-7: ['def subtract(a, b):', '    return a - b'], Modified Lines 6-7: ['def multiply(a, b):  # Changed subtract to multiply', \"    return a * b     # Changed '-' to '*'\"]\n",
            "Comments:\n",
            "This change looks good!\n",
            "Consider renaming 'add' function to 'sum'\n",
            "Documentation generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import difflib\n",
        "import tokenize\n",
        "from io import BytesIO\n",
        "\n",
        "# Semantic Analysis\n",
        "\n",
        "def analyze_semantics(code):\n",
        "    \"\"\"Perform semantic analysis on the given code.\"\"\"\n",
        "    # Example: check for undefined variables\n",
        "    try:\n",
        "        compiled_code = compile(code, '<string>', 'exec')\n",
        "        exec(compiled_code)\n",
        "    except Exception as e:\n",
        "        print(f\"Semantic error: {e}\")\n",
        "\n",
        "# Change Detection\n",
        "\n",
        "def detect_changes(original_code, modified_code):\n",
        "    \"\"\"Detect semantic changes between original and modified code.\"\"\"\n",
        "    original_ast = ast.parse(original_code)\n",
        "    modified_ast = ast.parse(modified_code)\n",
        "\n",
        "    # Compare ASTs to identify semantic changes\n",
        "    return not ast.dump(original_ast) == ast.dump(modified_ast)\n",
        "\n",
        "# Refactoring Detection\n",
        "\n",
        "def detect_refactorings(original_code, modified_code):\n",
        "    \"\"\"Detect refactorings between original and modified code.\"\"\"\n",
        "    # Example: check if variable names have changed\n",
        "    original_tokens = tokenize_code(original_code)\n",
        "    modified_tokens = tokenize_code(modified_code)\n",
        "    return original_tokens != modified_tokens\n",
        "\n",
        "# Code Diffing\n",
        "\n",
        "def compute_diff(original_code, modified_code):\n",
        "    \"\"\"Compute semantic differences between original and modified code.\"\"\"\n",
        "    original_lines = original_code.splitlines()\n",
        "    modified_lines = modified_code.splitlines()\n",
        "\n",
        "    diff = difflib.SequenceMatcher(None, original_lines, modified_lines).get_opcodes()\n",
        "\n",
        "    # Filter out non-essential differences\n",
        "    diff_info = []\n",
        "    for tag, i1, i2, j1, j2 in diff:\n",
        "        if tag == 'replace':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            # Check if the lines contain actual code\n",
        "            if any(line.strip() for line in original_content) or any(line.strip() for line in modified_content):\n",
        "                diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "        elif tag != 'equal':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "\n",
        "    return diff_info\n",
        "\n",
        "def tokenize_code(code):\n",
        "    \"\"\"Tokenize the given code.\"\"\"\n",
        "    tokens = []\n",
        "    code_bytes = BytesIO(code.encode('utf-8')).readline\n",
        "    try:\n",
        "        for token in tokenize.tokenize(code_bytes):\n",
        "            tokens.append(token)\n",
        "    except tokenize.TokenError:\n",
        "        pass  # Ignore tokenization errors\n",
        "    return tokens\n",
        "\n",
        "# Natural Language Processing (NLP)\n",
        "\n",
        "def analyze_commit_messages(commit_messages):\n",
        "    \"\"\"Analyze commit messages using NLP.\"\"\"\n",
        "    # Example: detect if the commit message contains keywords related to refactorings\n",
        "    for message in commit_messages:\n",
        "        if 'refactor' in message.lower():\n",
        "            print(\"Potential refactoring detected in commit message:\", message)\n",
        "\n",
        "# Collaborative Tools\n",
        "\n",
        "def provide_collaborative_feedback(code_diff, comments):\n",
        "    \"\"\"Provide collaborative feedback on code differences.\"\"\"\n",
        "    # Example: display code differences and allow developers to leave comments\n",
        "    print(\"Code differences:\")\n",
        "    for tag, i1, i2, j1, j2, orig_lines, mod_lines in code_diff:\n",
        "        print(f\"Operation: {tag}, Original Lines {i1}-{i2}: {orig_lines}, Modified Lines {j1}-{j2}: {mod_lines}\")\n",
        "    print(\"Comments:\")\n",
        "    for comment in comments:\n",
        "        print(comment)\n",
        "\n",
        "# Documentation and Tutorials\n",
        "\n",
        "def generate_documentation():\n",
        "    \"\"\"Generate documentation and tutorials for the tool.\"\"\"\n",
        "    # Example: generate documentation explaining tool usage, concepts, etc.\n",
        "    print(\"Documentation generated.\")\n",
        "\n",
        "# Main function\n",
        "\n",
        "def main():\n",
        "    # Define dataset paths\n",
        "    original_dataset_path = \"/content/original1.py\"\n",
        "    modified_dataset_path = \"/content/modified1.py\"\n",
        "\n",
        "    # Load datasets\n",
        "    with open(original_dataset_path, 'r') as original_file:\n",
        "        original_code = original_file.read()\n",
        "    with open(modified_dataset_path, 'r') as modified_file:\n",
        "        modified_code = modified_file.read()\n",
        "\n",
        "    # Example usage of functions\n",
        "    print(\"Output for original code:\")\n",
        "    exec(original_code)\n",
        "    print(\"\\nOutput for modified code:\")\n",
        "    exec(modified_code)\n",
        "\n",
        "    # Example usage of semantic analysis functions\n",
        "    analyze_semantics(original_code)\n",
        "    semantic_changes_detected = detect_changes(original_code, modified_code)\n",
        "    print(\"\\nSemantic Changes Detected:\", semantic_changes_detected)\n",
        "    refactoring_detected = detect_refactorings(original_code, modified_code)\n",
        "    print(\"Refactoring Detected:\", refactoring_detected)\n",
        "\n",
        "    # Compute code differences\n",
        "    opcodes = compute_diff(original_code, modified_code)\n",
        "\n",
        "    # Analyze commit messages\n",
        "    commit_messages = [\"Refactor the add function for clarity\", \"Fix bug in result calculation\"]\n",
        "    analyze_commit_messages(commit_messages)\n",
        "\n",
        "    # Provide collaborative feedback\n",
        "    comments = [\"This change looks good!\", \"Consider renaming 'add' function to 'sum'\"]\n",
        "    provide_collaborative_feedback(opcodes, comments)\n",
        "\n",
        "    # Generate documentation\n",
        "    generate_documentation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd0BuT-J_dIb",
        "outputId": "3a974576-b3d8-4b46-f493-b5883e756387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for original code:\n",
            "\n",
            "Output for modified code:\n",
            "\n",
            "Semantic Changes Detected: True\n",
            "Refactoring Detected: True\n",
            "Potential refactoring detected in commit message: Refactor the add function for clarity\n",
            "Code differences:\n",
            "Operation: replace, Original Lines 2-2: [\"original_code = '''\"], Modified Lines 2-2: [\"modified_code = '''\"]\n",
            "Operation: replace, Original Lines 12-12: ['    {\"name\": \"Product C\", \"quantity\": 3, \"price_per_unit\": 7.99}'], Modified Lines 12-12: ['    {\"name\": \"Product D\", \"quantity\": 4, \"price_per_unit\": 12.99}']\n",
            "Operation: delete, Original Lines 21-21: [''], Modified Lines 21-20: []\n",
            "Comments:\n",
            "This change looks good!\n",
            "Consider renaming 'add' function to 'sum'\n",
            "Documentation generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import difflib\n",
        "import tokenize\n",
        "from io import BytesIO\n",
        "\n",
        "# Semantic Analysis\n",
        "\n",
        "def analyze_semantics(code):\n",
        "    \"\"\"Perform semantic analysis on the given code.\"\"\"\n",
        "    # Example: check for undefined variables\n",
        "    try:\n",
        "        compiled_code = compile(code, '<string>', 'exec')\n",
        "        exec(compiled_code)\n",
        "    except Exception as e:\n",
        "        print(f\"Semantic error: {e}\")\n",
        "\n",
        "# Change Detection\n",
        "\n",
        "def detect_changes(original_code, modified_code):\n",
        "    \"\"\"Detect semantic changes between original and modified code.\"\"\"\n",
        "    original_ast = ast.parse(original_code)\n",
        "    modified_ast = ast.parse(modified_code)\n",
        "\n",
        "    # Compare ASTs to identify semantic changes\n",
        "    return not ast.dump(original_ast) == ast.dump(modified_ast)\n",
        "\n",
        "# Refactoring Detection\n",
        "\n",
        "def detect_refactorings(original_code, modified_code):\n",
        "    \"\"\"Detect refactorings between original and modified code.\"\"\"\n",
        "    # Example: check if variable names have changed\n",
        "    original_tokens = tokenize_code(original_code)\n",
        "    modified_tokens = tokenize_code(modified_code)\n",
        "    return original_tokens != modified_tokens\n",
        "\n",
        "# Code Diffing\n",
        "\n",
        "def compute_diff(original_code, modified_code):\n",
        "    \"\"\"Compute semantic differences between original and modified code.\"\"\"\n",
        "    original_lines = original_code.splitlines()\n",
        "    modified_lines = modified_code.splitlines()\n",
        "\n",
        "    diff = difflib.SequenceMatcher(None, original_lines, modified_lines).get_opcodes()\n",
        "\n",
        "    # Filter out non-essential differences\n",
        "    diff_info = []\n",
        "    for tag, i1, i2, j1, j2 in diff:\n",
        "        if tag == 'replace':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            # Check if the lines contain actual code\n",
        "            if any(line.strip() for line in original_content) or any(line.strip() for line in modified_content):\n",
        "                diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "        elif tag != 'equal':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "\n",
        "    return diff_info\n",
        "\n",
        "def tokenize_code(code):\n",
        "    \"\"\"Tokenize the given code.\"\"\"\n",
        "    tokens = []\n",
        "    code_bytes = BytesIO(code.encode('utf-8')).readline\n",
        "    try:\n",
        "        for token in tokenize.tokenize(code_bytes):\n",
        "            tokens.append(token)\n",
        "    except tokenize.TokenError:\n",
        "        pass  # Ignore tokenization errors\n",
        "    return tokens\n",
        "\n",
        "# Natural Language Processing (NLP)\n",
        "\n",
        "def analyze_commit_messages(commit_messages):\n",
        "    \"\"\"Analyze commit messages using NLP.\"\"\"\n",
        "    # Example: detect if the commit message contains keywords related to refactorings\n",
        "    for message in commit_messages:\n",
        "        if 'refactor' in message.lower():\n",
        "            print(\"Potential refactoring detected in commit message:\", message)\n",
        "\n",
        "# Collaborative Tools\n",
        "\n",
        "def provide_collaborative_feedback(code_diff, comments):\n",
        "    \"\"\"Provide collaborative feedback on code differences.\"\"\"\n",
        "    # Example: display code differences and allow developers to leave comments\n",
        "    print(\"Code differences:\")\n",
        "    for tag, i1, i2, j1, j2, orig_lines, mod_lines in code_diff:\n",
        "        print(f\"Operation: {tag}, Original Lines {i1}-{i2}: {orig_lines}, Modified Lines {j1}-{j2}: {mod_lines}\")\n",
        "    print(\"Comments:\")\n",
        "    for comment in comments:\n",
        "        print(comment)\n",
        "\n",
        "# Documentation and Tutorials\n",
        "\n",
        "def generate_documentation():\n",
        "    \"\"\"Generate documentation and tutorials for the tool.\"\"\"\n",
        "    # Example: generate documentation explaining tool usage, concepts, etc.\n",
        "    print(\"Documentation generated.\")\n",
        "\n",
        "# Main function\n",
        "\n",
        "def main():\n",
        "    # Define dataset paths\n",
        "    original_dataset_path = \"/content/original2.py\"\n",
        "    modified_dataset_path = \"/content/modified2.py\"\n",
        "\n",
        "    # Load datasets\n",
        "    with open(original_dataset_path, 'r') as original_file:\n",
        "        original_code = original_file.read()\n",
        "    with open(modified_dataset_path, 'r') as modified_file:\n",
        "        modified_code = modified_file.read()\n",
        "\n",
        "    # Define the factorial function\n",
        "    def factorial(n):\n",
        "        if n == 0:\n",
        "            return 1\n",
        "        else:\n",
        "            return n * factorial(n-1)\n",
        "\n",
        "    # Example usage of functions\n",
        "    print(\"Output for original code:\")\n",
        "    exec(original_code, globals())\n",
        "    print(\"\\nOutput for modified code:\")\n",
        "    exec(modified_code, globals())\n",
        "\n",
        "    # Example usage of semantic analysis functions\n",
        "    analyze_semantics(original_code)\n",
        "    semantic_changes_detected = detect_changes(original_code, modified_code)\n",
        "    print(\"\\nSemantic Changes Detected:\", semantic_changes_detected)\n",
        "    refactoring_detected = detect_refactorings(original_code, modified_code)\n",
        "    print(\"Refactoring Detected:\", refactoring_detected)\n",
        "\n",
        "    # Compute code differences\n",
        "    opcodes = compute_diff(original_code, modified_code)\n",
        "\n",
        "    # Analyze commit messages\n",
        "    commit_messages = [\"Refactor the add function for clarity\", \"Fix bug in result calculation\"]\n",
        "    analyze_commit_messages(commit_messages)\n",
        "\n",
        "    # Provide collaborative feedback\n",
        "    comments = [\"This change looks good!\", \"Consider renaming 'add' function to 'sum'\"]\n",
        "    provide_collaborative_feedback(opcodes, comments)\n",
        "\n",
        "    # Generate documentation\n",
        "    generate_documentation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krF1IWEsAR1i",
        "outputId": "4fd74549-9f02-4599-ce7d-90e79c0ec47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for original code:\n",
            "Factorial of 10: 3628800\n",
            "Fibonacci sequence up to 10: 0 1 1 2 3 5 8 13 21 34 \n",
            "Prime numbers up to 10 : [2, 3, 5, 7]\n",
            "\n",
            "Output for modified code:\n",
            "Factorial of 15: 1307674368000\n",
            "Fibonacci sequence up to 15: 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 \n",
            "Prime numbers up to 15 : [2, 3, 5, 7, 11, 13]\n",
            "Factorial of 10: 3628800\n",
            "Fibonacci sequence up to 10: 0 1 1 2 3 5 8 13 21 34 \n",
            "Prime numbers up to 10 : [2, 3, 5, 7]\n",
            "\n",
            "Semantic Changes Detected: True\n",
            "Refactoring Detected: True\n",
            "Potential refactoring detected in commit message: Refactor the add function for clarity\n",
            "Code differences:\n",
            "Operation: replace, Original Lines 29-29: ['number = 10'], Modified Lines 29-29: ['number = 15']\n",
            "Comments:\n",
            "This change looks good!\n",
            "Consider renaming 'add' function to 'sum'\n",
            "Documentation generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import difflib\n",
        "import tokenize\n",
        "from io import BytesIO\n",
        "\n",
        "# Semantic Analysis\n",
        "\n",
        "def analyze_semantics(code):\n",
        "    \"\"\"Perform semantic analysis on the given code.\"\"\"\n",
        "    # Example: check for undefined variables\n",
        "    try:\n",
        "        compiled_code = compile(code, '<string>', 'exec')\n",
        "        exec(compiled_code)\n",
        "    except Exception as e:\n",
        "        print(f\"Semantic error: {e}\")\n",
        "\n",
        "# Change Detection\n",
        "\n",
        "def detect_changes(original_code, modified_code):\n",
        "    \"\"\"Detect semantic changes between original and modified code.\"\"\"\n",
        "    original_ast = ast.parse(original_code)\n",
        "    modified_ast = ast.parse(modified_code)\n",
        "\n",
        "    # Compare ASTs to identify semantic changes\n",
        "    return not ast.dump(original_ast) == ast.dump(modified_ast)\n",
        "\n",
        "# Refactoring Detection\n",
        "\n",
        "def detect_refactorings(original_code, modified_code):\n",
        "    \"\"\"Detect refactorings between original and modified code.\"\"\"\n",
        "    # Example: check if variable names have changed\n",
        "    original_tokens = tokenize_code(original_code)\n",
        "    modified_tokens = tokenize_code(modified_code)\n",
        "    return original_tokens != modified_tokens\n",
        "\n",
        "# Code Diffing\n",
        "\n",
        "def compute_diff(original_code, modified_code):\n",
        "    \"\"\"Compute semantic differences between original and modified code.\"\"\"\n",
        "    original_lines = original_code.splitlines()\n",
        "    modified_lines = modified_code.splitlines()\n",
        "\n",
        "    diff = difflib.SequenceMatcher(None, original_lines, modified_lines).get_opcodes()\n",
        "\n",
        "    # Filter out non-essential differences\n",
        "    diff_info = []\n",
        "    for tag, i1, i2, j1, j2 in diff:\n",
        "        if tag == 'replace':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            # Check if the lines contain actual code\n",
        "            if any(line.strip() for line in original_content) or any(line.strip() for line in modified_content):\n",
        "                diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "        elif tag != 'equal':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "\n",
        "    return diff_info\n",
        "\n",
        "def tokenize_code(code):\n",
        "    \"\"\"Tokenize the given code.\"\"\"\n",
        "    tokens = []\n",
        "    code_bytes = BytesIO(code.encode('utf-8')).readline\n",
        "    try:\n",
        "        for token in tokenize.tokenize(code_bytes):\n",
        "            tokens.append(token)\n",
        "    except tokenize.TokenError:\n",
        "        pass  # Ignore tokenization errors\n",
        "    return tokens\n",
        "\n",
        "# Natural Language Processing (NLP)\n",
        "\n",
        "def analyze_commit_messages(commit_messages):\n",
        "    \"\"\"Analyze commit messages using NLP.\"\"\"\n",
        "    # Example: detect if the commit message contains keywords related to refactorings\n",
        "    for message in commit_messages:\n",
        "        if 'refactor' in message.lower():\n",
        "            print(\"Potential refactoring detected in commit message:\", message)\n",
        "\n",
        "# Collaborative Tools\n",
        "\n",
        "def provide_collaborative_feedback(code_diff, comments):\n",
        "    \"\"\"Provide collaborative feedback on code differences.\"\"\"\n",
        "    # Example: display code differences and allow developers to leave comments\n",
        "    print(\"Code differences:\")\n",
        "    for tag, i1, i2, j1, j2, orig_lines, mod_lines in code_diff:\n",
        "        print(f\"Operation: {tag}, Original Lines {i1}-{i2}: {orig_lines}, Modified Lines {j1}-{j2}: {mod_lines}\")\n",
        "    print(\"Comments:\")\n",
        "    for comment in comments:\n",
        "        print(comment)\n",
        "\n",
        "# Documentation and Tutorials\n",
        "\n",
        "def generate_documentation():\n",
        "    \"\"\"Generate documentation and tutorials for the tool.\"\"\"\n",
        "    # Example: generate documentation explaining tool usage, concepts, etc.\n",
        "    print(\"Documentation generated.\")\n",
        "\n",
        "# Main function\n",
        "\n",
        "def main():\n",
        "    # Define dataset paths\n",
        "    original_dataset_path = \"/content/original3.py\"\n",
        "    modified_dataset_path = \"/content/modified3.py\"\n",
        "\n",
        "    # Load datasets\n",
        "    with open(original_dataset_path, 'r') as original_file:\n",
        "        original_code = original_file.read()\n",
        "    with open(modified_dataset_path, 'r') as modified_file:\n",
        "        modified_code = modified_file.read()\n",
        "\n",
        "    # Example usage of functions\n",
        "    print(\"Output for original code:\")\n",
        "    exec(original_code)\n",
        "    print(\"\\nOutput for modified code:\")\n",
        "    exec(modified_code)\n",
        "\n",
        "    # Example usage of semantic analysis functions\n",
        "    analyze_semantics(original_code)\n",
        "    semantic_changes_detected = detect_changes(original_code, modified_code)\n",
        "    print(\"\\nSemantic Changes Detected:\", semantic_changes_detected)\n",
        "    refactoring_detected = detect_refactorings(original_code, modified_code)\n",
        "    print(\"Refactoring Detected:\", refactoring_detected)\n",
        "\n",
        "    # Compute code differences\n",
        "    opcodes = compute_diff(original_code, modified_code)\n",
        "\n",
        "    # Analyze commit messages\n",
        "    commit_messages = [\"Refactor the add function for clarity\", \"Fix bug in result calculation\"]\n",
        "    analyze_commit_messages(commit_messages)\n",
        "\n",
        "    # Provide collaborative feedback\n",
        "    comments = [\"This change looks good!\", \"Consider renaming 'add' function to 'sum'\"]\n",
        "    provide_collaborative_feedback(opcodes, comments)\n",
        "\n",
        "    # Generate documentation\n",
        "    generate_documentation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8QM0E8UAVMG",
        "outputId": "83170fab-8535-4147-d8d1-3a19b0c6a2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for original code:\n",
            "Sorted array: [11, 12, 22, 25, 34, 64, 90]\n",
            "Element 25 is present at index 3\n",
            "\n",
            "Output for modified code:\n",
            "Sorted array: [11, 12, 19, 22, 25, 34, 45, 64, 72, 90]\n",
            "Element 19 is present at index 2\n",
            "Sorted array: [11, 12, 22, 25, 34, 64, 90]\n",
            "Element 25 is present at index 3\n",
            "\n",
            "Semantic Changes Detected: True\n",
            "Refactoring Detected: True\n",
            "Potential refactoring detected in commit message: Refactor the add function for clarity\n",
            "Code differences:\n",
            "Operation: replace, Original Lines 23-23: ['arr = [64, 34, 25, 12, 22, 11, 90]'], Modified Lines 23-23: ['arr = [64, 34, 25, 12, 22, 11, 90, 45, 19, 72]']\n",
            "Operation: replace, Original Lines 26-26: ['target = 25'], Modified Lines 26-26: ['target = 19']\n",
            "Comments:\n",
            "This change looks good!\n",
            "Consider renaming 'add' function to 'sum'\n",
            "Documentation generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import difflib\n",
        "import tokenize\n",
        "from io import BytesIO\n",
        "\n",
        "# Semantic Analysis\n",
        "\n",
        "def analyze_semantics(code):\n",
        "    \"\"\"Perform semantic analysis on the given code.\"\"\"\n",
        "    # Example: check for undefined variables\n",
        "    try:\n",
        "        compiled_code = compile(code, '<string>', 'exec')\n",
        "        exec(compiled_code)\n",
        "    except Exception as e:\n",
        "        print(f\"Semantic error: {e}\")\n",
        "\n",
        "# Change Detection\n",
        "\n",
        "def detect_changes(original_code, modified_code):\n",
        "    \"\"\"Detect semantic changes between original and modified code.\"\"\"\n",
        "    original_ast = ast.parse(original_code)\n",
        "    modified_ast = ast.parse(modified_code)\n",
        "\n",
        "    # Compare ASTs to identify semantic changes\n",
        "    return not ast.dump(original_ast) == ast.dump(modified_ast)\n",
        "\n",
        "# Refactoring Detection\n",
        "\n",
        "def detect_refactorings(original_code, modified_code):\n",
        "    \"\"\"Detect refactorings between original and modified code.\"\"\"\n",
        "    # Example: check if variable names have changed\n",
        "    original_tokens = tokenize_code(original_code)\n",
        "    modified_tokens = tokenize_code(modified_code)\n",
        "    return original_tokens != modified_tokens\n",
        "\n",
        "# Code Diffing\n",
        "\n",
        "def compute_diff(original_code, modified_code):\n",
        "    \"\"\"Compute semantic differences between original and modified code.\"\"\"\n",
        "    original_lines = original_code.splitlines()\n",
        "    modified_lines = modified_code.splitlines()\n",
        "\n",
        "    diff = difflib.SequenceMatcher(None, original_lines, modified_lines).get_opcodes()\n",
        "\n",
        "    # Filter out non-essential differences\n",
        "    diff_info = []\n",
        "    for tag, i1, i2, j1, j2 in diff:\n",
        "        if tag == 'replace':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            # Check if the lines contain actual code\n",
        "            if any(line.strip() for line in original_content) or any(line.strip() for line in modified_content):\n",
        "                diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "        elif tag != 'equal':\n",
        "            original_content = original_lines[i1:i2]\n",
        "            modified_content = modified_lines[j1:j2]\n",
        "            diff_info.append((tag, i1+1, i2, j1+1, j2, original_content, modified_content))\n",
        "\n",
        "    return diff_info\n",
        "\n",
        "def tokenize_code(code):\n",
        "    \"\"\"Tokenize the given code.\"\"\"\n",
        "    tokens = []\n",
        "    code_bytes = BytesIO(code.encode('utf-8')).readline\n",
        "    try:\n",
        "        for token in tokenize.tokenize(code_bytes):\n",
        "            tokens.append(token)\n",
        "    except tokenize.TokenError:\n",
        "        pass  # Ignore tokenization errors\n",
        "    return tokens\n",
        "\n",
        "# Natural Language Processing (NLP)\n",
        "\n",
        "def analyze_commit_messages(commit_messages):\n",
        "    \"\"\"Analyze commit messages using NLP.\"\"\"\n",
        "    # Example: detect if the commit message contains keywords related to refactorings\n",
        "    for message in commit_messages:\n",
        "        if 'refactor' in message.lower():\n",
        "            print(\"Potential refactoring detected in commit message:\", message)\n",
        "\n",
        "# Collaborative Tools\n",
        "\n",
        "def provide_collaborative_feedback(code_diff, comments):\n",
        "    \"\"\"Provide collaborative feedback on code differences.\"\"\"\n",
        "    # Example: display code differences and allow developers to leave comments\n",
        "    print(\"Code differences:\")\n",
        "    for tag, i1, i2, j1, j2, orig_lines, mod_lines in code_diff:\n",
        "        print(f\"Operation: {tag}, Original Lines {i1}-{i2}: {orig_lines}, Modified Lines {j1}-{j2}: {mod_lines}\")\n",
        "    print(\"Comments:\")\n",
        "    for comment in comments:\n",
        "        print(comment)\n",
        "\n",
        "# Documentation and Tutorials\n",
        "\n",
        "def generate_documentation():\n",
        "    \"\"\"Generate documentation and tutorials for the tool.\"\"\"\n",
        "    # Example: generate documentation explaining tool usage, concepts, etc.\n",
        "    print(\"Documentation generated.\")\n",
        "\n",
        "# Main function\n",
        "\n",
        "def main():\n",
        "    # Define dataset paths\n",
        "    original_dataset_path = \"/content/original4.py\"\n",
        "    modified_dataset_path = \"/content/modified4.py\"\n",
        "\n",
        "    # Load datasets\n",
        "    with open(original_dataset_path, 'r') as original_file:\n",
        "        original_code = original_file.read()\n",
        "    with open(modified_dataset_path, 'r') as modified_file:\n",
        "        modified_code = modified_file.read()\n",
        "\n",
        "    # Example usage of functions\n",
        "    print(\"Output for original code:\")\n",
        "    exec(original_code)\n",
        "    print(\"\\nOutput for modified code:\")\n",
        "    exec(modified_code)\n",
        "\n",
        "    # Example usage of semantic analysis functions\n",
        "    analyze_semantics(original_code)\n",
        "    semantic_changes_detected = detect_changes(original_code, modified_code)\n",
        "    print(\"\\nSemantic Changes Detected:\", semantic_changes_detected)\n",
        "    refactoring_detected = detect_refactorings(original_code, modified_code)\n",
        "    print(\"Refactoring Detected:\", refactoring_detected)\n",
        "\n",
        "    # Compute code differences\n",
        "    opcodes = compute_diff(original_code, modified_code)\n",
        "\n",
        "    # Analyze commit messages\n",
        "    commit_messages = [\"Refactor the add function for clarity\", \"Fix bug in result calculation\"]\n",
        "    analyze_commit_messages(commit_messages)\n",
        "\n",
        "\n",
        "    # Provide collaborative feedback\n",
        "    comments = [\"This change looks good!\", \"Consider renaming 'add' function to 'sum'\"]\n",
        "    provide_collaborative_feedback(opcodes, comments)\n",
        "\n",
        "    # Generate documentation\n",
        "    generate_documentation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QEAOVhyBNHn",
        "outputId": "4eb59ff2-c25e-4cf7-83ec-f67e498f572f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for original code:\n",
            "Area of circle with radius 5 : 78.5\n",
            "Element 4 found at index 0\n",
            "Array with duplicates removed: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "\n",
            "Output for modified code:\n",
            "Area of circle with radius 7 : 153.93791\n",
            "Element 14 found at index 4\n",
            "Array after inserting 6 in sorted order: [1, 3, 5, 6, 7, 9]\n",
            "Area of circle with radius 5 : 78.5\n",
            "Element 4 found at index 0\n",
            "Array with duplicates removed: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "\n",
            "Semantic Changes Detected: True\n",
            "Refactoring Detected: True\n",
            "Potential refactoring detected in commit message: Refactor the add function for clarity\n",
            "Code differences:\n",
            "Operation: replace, Original Lines 3-3: ['    return 3.14 * radius ** 2'], Modified Lines 3-3: ['    return 3.14159 * radius ** 2']\n",
            "Operation: replace, Original Lines 11-16: ['def remove_duplicates(arr):', '    unique_arr = []', '    for item in arr:', '        if item not in unique_arr:', '            unique_arr.append(item)', '    return unique_arr'], Modified Lines 11-17: ['def insert_sorted(arr, value):', '    for i in range(len(arr)):', '        if arr[i] > value:', '            arr.insert(i, value)', '            return arr', '    arr.append(value)', '    return arr']\n",
            "Operation: replace, Original Lines 19-19: ['radius = 5'], Modified Lines 20-20: ['radius = 7']\n",
            "Operation: replace, Original Lines 22-23: ['numbers = [4, 8, 2, 10, 4, 6, 8]', 'target = 4'], Modified Lines 23-24: ['numbers = [2, 6, 8, 10, 14, 18]', 'target = 14']\n",
            "Operation: replace, Original Lines 30-32: ['values = [1, 2, 3, 2, 4, 5, 6, 1, 7, 8, 9]', 'unique_values = remove_duplicates(values)', 'print(\"Array with duplicates removed:\", unique_values)'], Modified Lines 31-34: ['values = [1, 3, 5, 7, 9]', 'new_value = 6', 'updated_values = insert_sorted(values, new_value)', 'print(\"Array after inserting\", new_value, \"in sorted order:\", updated_values)']\n",
            "Comments:\n",
            "This change looks good!\n",
            "Consider renaming 'add' function to 'sum'\n",
            "Documentation generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BmldbJr-BXa9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}